{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsadaphule/jhu-dnn/blob/main/5%F0%9F%8F%86%F0%9F%9B%92Shop_Final_v4_Team_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<small><font color=gray>Notebook author: <a href=\"https://www.linkedin.com/in/olegmelnikov/\" target=\"_blank\">Oleg Melnikov</a> ©2021 onwards</font></small><hr style=\"margin:0;background-color:silver\">\n",
        "\n",
        "**[<font size=6>🛒Shop</font>](https://www.kaggle.com/competitions/26jun23jh-shop/rules)**. [**Instructions**](https://colab.research.google.com/drive/1riOGrE_Fv-yfIbM5V4pgJx4DWcd92cZr#scrollTo=ITaPDPIQEgXV) for running Colabs."
      ],
      "metadata": {
        "id": "q3pqxgX4DxeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<small>**(Optional) CONSENT.** <mark>[ X ]</mark> We consent to sharing our Colab (after the assignment ends) with other students/instructors for educational purposes. We understand that sharing is optional and this decision will not affect our grade in any way. <font color=gray><i>(If ok with sharing your Colab for educational purposes, leave \"X\" in the check box.)</i></font></small>"
      ],
      "metadata": {
        "id": "-QkDG8eYL75n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive; drive.mount('/content/drive')   # OK to enable, if your kaggle.json is stored in Google Drive"
      ],
      "metadata": {
        "id": "qrogZ_8bD9tZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ebd3e3-3cb9-4efc-d630-5c5bbc939bb9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8XoC8VqBXGs",
        "outputId": "77155a86-783d-4478-e064-46d191a5e8ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "- competition is now set to: 26jun23jh-shop\n",
            "100% 9.98M/9.98M [00:00<00:00, 242MB/s]\n",
            "Using competition: 26jun23jh-shop\n",
            "  teamId  teamName             submissionDate       score    \n",
            "--------  -------------------  -------------------  -------  \n",
            "10631355  Group 9              2023-07-08 16:44:24  0.99324  \n",
            "10638614  Alayna Stepp         2023-07-06 01:34:40  0.99272  \n",
            "10638830  Team 13              2023-07-08 23:34:21  0.99008  \n",
            "10652071  Ryan Dombrowski      2023-07-09 12:06:17  0.98744  \n",
            "10644064  Group 2              2023-07-09 09:33:04  0.98732  \n",
            "10654893  NeilJoshi            2023-07-09 05:36:25  0.98684  \n",
            "10639155  Jooyoung Park        2023-07-09 06:36:04  0.98672  \n",
            "10633911  Group 11             2023-07-09 03:37:52  0.98640  \n",
            "10638103  Group 15             2023-07-08 03:16:47  0.98588  \n",
            "10635224  Margarita Prikhodko  2023-07-09 04:21:31  0.98256  \n",
            "10642846  Group 14             2023-07-08 21:37:22  0.98232  \n",
            "10637839  Larry Walker         2023-07-08 22:16:01  0.98124  \n",
            "10605620  Group 3              2023-07-09 00:44:31  0.97936  \n",
            "10631543  Lohith Muppala       2023-07-09 00:06:12  0.97124  \n",
            "10638955  Group 6              2023-07-09 04:45:59  0.96556  \n",
            "10638261  Group 10             2023-07-08 22:46:21  0.95268  \n",
            "10632500  Matt Sunday          2023-07-08 19:40:02  0.91916  \n",
            "10642310  Ravindra Sadaphule   2023-07-08 18:44:44  0.89204  \n",
            "10635178  Lu Liu               2023-07-09 00:26:45  0.89184  \n",
            "10642713  Shawn Simon          2023-07-09 04:58:56  0.88900  \n",
            "10634506  Chuck de Sully       2023-07-09 11:51:35  0.88432  \n",
            "10614691  Group 16             2023-07-09 00:52:43  0.87844  \n",
            "10634431  JaneC                2023-07-06 21:21:08  0.86968  \n",
            "10635435  Group 5              2023-07-08 13:21:51  0.85496  \n",
            "10654424  Dzmitry Kasinets     2023-07-08 23:43:59  0.83872  \n",
            "10631821  Brian Yang           2023-07-08 05:57:51  0.83000  \n",
            "10637941  Pratik Jasani        2023-07-08 22:33:24  0.82260  \n",
            "10654817  Noah Burkhardt       2023-07-09 10:01:58  0.81968  \n",
            "10647334  Chris Symons         2023-07-08 23:57:48  0.81952  \n",
            "10634536  yjung2976            2023-07-05 20:39:55  0.81692  \n",
            "10637353  Vincent Kowalski     2023-07-08 07:24:09  0.81444  \n",
            "10643380  Rebecca John         2023-07-06 15:11:30  0.81304  \n",
            "10588281  🛒Baseline🐍           2023-06-21 13:13:26  0.80444  \n"
          ]
        }
      ],
      "source": [
        "!pip -q install --upgrade --force-reinstall --no-deps kaggle > log  # upgrade kaggle package (to avoid a warning)\n",
        "!mkdir -p ~/.kaggle                               # .kaggle folder must contain kaggle.json for kaggle executable to properly authenticate you to Kaggle.com\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json >log  # First, download kaggle.json from kaggle.com (in Account page) and place it in the root of mounted Google Drive\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json > log       # Alternative location of kaggle.json (without a connection to Google Drive)\n",
        "!chmod 600 ~/.kaggle/kaggle.json                  # give only the owner full read/write access to kaggle.json\n",
        "!kaggle config set -n competition -v 26jun23jh-shop    # set the competition context for the next few kaggle API calls. !kaggle config view - shows current settings\n",
        "!kaggle competitions download >> log              # download competition dataset as a zip file\n",
        "!unzip -o *.zip >> log                            # Kaggle dataset is copied as a single file and needs to be unzipped.\n",
        "!kaggle competitions leaderboard --show           # print public leaderboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U tensorflow_addons > log"
      ],
      "metadata": {
        "id": "5Iie9fjWKwpV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%%capture\n",
        "%reset -f\n",
        "from IPython.core.interactiveshell import InteractiveShell as IS; IS.ast_node_interactivity = \"all\"\n",
        "import numpy as np, pandas as pd, time, matplotlib.pyplot as plt, seaborn as sns, tensorflow_addons as tfa\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import tensorflow as tf, tensorflow.keras as keras\n",
        "from keras.layers import Flatten, Dense\n",
        "ToCSV = lambda df, fname: df.round(2).to_csv(f'{fname}.csv', index_label='id') # rounds values to 2 decimals\n",
        "\n",
        "class Timer():\n",
        "  def __init__(self, lim:'RunTimeLimit'=60): self.t0, self.lim, _ = time.time(), lim, print(f'⏳ started. You have {lim} sec. Good luck!')\n",
        "  def ShowTime(self):\n",
        "    msg = f'Runtime is {time.time()-self.t0:.0f} sec'\n",
        "    print(f'\\033[91m\\033[1m' + msg + f' > {self.lim} sec limit!!!\\033[0m' if (time.time()-self.t0-1) > self.lim else msg)\n",
        "\n",
        "np.set_printoptions(linewidth=100, precision=2, edgeitems=2, suppress=True)\n",
        "pd.set_option('display.max_columns', 20, 'display.precision', 2, 'display.max_rows', 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CyC-JlZFga1",
        "outputId": "91b545d7-ffe3-46fa-fc73-fbca54d333c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.5 s, sys: 608 ms, total: 7.11 s\n",
            "Wall time: 11.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('XY_Shop.csv'); df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "X00bQLb5FpxU",
        "outputId": "c63c5bd8-acb5-4595-f3d0-8290fb304dc9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Adm  AdmDur  Inf  InfDur  Prd   PrdDur     BncRt     ExtRt  PgVal  \\\n",
              "0         0    0.00    0     0.0   18   132.99  3.82e-02  5.45e-02    0.0   \n",
              "1         1    0.00    0     0.0   37  1150.20  1.25e-03  3.03e-02    0.0   \n",
              "...     ...     ...  ...     ...  ...      ...       ...       ...    ...   \n",
              "499998    0    0.00    0     0.0   27  1185.14  0.00e+00  1.59e-03    0.0   \n",
              "499999    6   51.36    0     0.0   59  1898.21  0.00e+00  3.22e-03    0.0   \n",
              "\n",
              "        SpclDay  Mo  OS  Bsr  Rgn  TfcTp  VstTp  Wkd  Rev  \n",
              "0           0.0   4   3    1    1      2      0    1  NaN  \n",
              "1           0.0  11   2    2    4      2      0    1  NaN  \n",
              "...         ...  ..  ..  ...  ...    ...    ...  ...  ...  \n",
              "499998      0.0   5   2    2    2      3      0    1  0.0  \n",
              "499999      0.0  12   2    2    2      1      0    0  0.0  \n",
              "\n",
              "[500000 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60a75c61-bd8a-42e3-ad93-aa6b0fe82218\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Adm</th>\n",
              "      <th>AdmDur</th>\n",
              "      <th>Inf</th>\n",
              "      <th>InfDur</th>\n",
              "      <th>Prd</th>\n",
              "      <th>PrdDur</th>\n",
              "      <th>BncRt</th>\n",
              "      <th>ExtRt</th>\n",
              "      <th>PgVal</th>\n",
              "      <th>SpclDay</th>\n",
              "      <th>Mo</th>\n",
              "      <th>OS</th>\n",
              "      <th>Bsr</th>\n",
              "      <th>Rgn</th>\n",
              "      <th>TfcTp</th>\n",
              "      <th>VstTp</th>\n",
              "      <th>Wkd</th>\n",
              "      <th>Rev</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18</td>\n",
              "      <td>132.99</td>\n",
              "      <td>3.82e-02</td>\n",
              "      <td>5.45e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37</td>\n",
              "      <td>1150.20</td>\n",
              "      <td>1.25e-03</td>\n",
              "      <td>3.03e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499998</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27</td>\n",
              "      <td>1185.14</td>\n",
              "      <td>0.00e+00</td>\n",
              "      <td>1.59e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499999</th>\n",
              "      <td>6</td>\n",
              "      <td>51.36</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59</td>\n",
              "      <td>1898.21</td>\n",
              "      <td>0.00e+00</td>\n",
              "      <td>3.22e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500000 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60a75c61-bd8a-42e3-ad93-aa6b0fe82218')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60a75c61-bd8a-42e3-ad93-aa6b0fe82218 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60a75c61-bd8a-42e3-ad93-aa6b0fe82218');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()   # observe datatypes and any missing values"
      ],
      "metadata": {
        "id": "fFp0IV3BJR9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a11af01c-bd21-447e-a4cd-ac6aaa3ce0ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500000 entries, 0 to 499999\n",
            "Data columns (total 18 columns):\n",
            " #   Column   Non-Null Count   Dtype  \n",
            "---  ------   --------------   -----  \n",
            " 0   Adm      500000 non-null  int64  \n",
            " 1   AdmDur   500000 non-null  float64\n",
            " 2   Inf      500000 non-null  int64  \n",
            " 3   InfDur   500000 non-null  float64\n",
            " 4   Prd      500000 non-null  int64  \n",
            " 5   PrdDur   500000 non-null  float64\n",
            " 6   BncRt    500000 non-null  float64\n",
            " 7   ExtRt    500000 non-null  float64\n",
            " 8   PgVal    500000 non-null  float64\n",
            " 9   SpclDay  500000 non-null  float64\n",
            " 10  Mo       500000 non-null  int64  \n",
            " 11  OS       500000 non-null  int64  \n",
            " 12  Bsr      500000 non-null  int64  \n",
            " 13  Rgn      500000 non-null  int64  \n",
            " 14  TfcTp    500000 non-null  int64  \n",
            " 15  VstTp    500000 non-null  int64  \n",
            " 16  Wkd      500000 non-null  int64  \n",
            " 17  Rev      450000 non-null  float64\n",
            "dtypes: float64(8), int64(10)\n",
            "memory usage: 68.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vX = df.query('Rev!=Rev').drop('Rev', axis=1)  # slice a test sample\n",
        "tXY = df.query('Rev==Rev')                     # slice training sample\n",
        "tX, tY = tXY.drop('Rev', axis=1), tXY.Rev      # split into training I/O\n",
        "NumFeatures = list(tX.select_dtypes(include='float').columns)\n",
        "print('Numeric features: ', NumFeatures)       # numeric/quantitative feature names"
      ],
      "metadata": {
        "id": "f7OuVizOFsFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40db8bf9-b363-492f-ee29-93ae8a55ead4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric features:  ['AdmDur', 'InfDur', 'PrdDur', 'BncRt', 'ExtRt', 'PgVal', 'SpclDay']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WA8pIRj5RRUi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def ScatterCorrHist(df):\n",
        "#   def corrdot(*args, **kwargs):\n",
        "#     # credit: https://stackoverflow.com/questions/48139899\n",
        "#     corr_r = args[0].corr(args[1], 'pearson')\n",
        "#     corr_text = f\"{corr_r:2.2f}\".replace(\"0.\", \".\")\n",
        "#     ax = plt.gca();\n",
        "#     ax.set_axis_off();\n",
        "#     msz = abs(corr_r) * 5000   # marker size\n",
        "#     fsz = abs(corr_r) * 40 + 5 # font size\n",
        "#     ax.scatter([.5], [.5], msz, [corr_r], alpha=0.5, cmap='coolwarm', vmin=-1, vmax=1, transform=ax.transAxes)\n",
        "#     ax.annotate(corr_text, [.5, .5,],  xycoords=\"axes fraction\", ha='center', va='center', fontsize=fsz)\n",
        "\n",
        "#   sns.set(style='white', font_scale=.8);\n",
        "#   g = sns.PairGrid(df, aspect=1, diag_sharey=False);\n",
        "#   g.fig.set_size_inches(20,10)\n",
        "#   g.map_lower(sns.regplot, lowess=True, ci=False, line_kws={'color':'red'}, scatter_kws={'s':1});\n",
        "#   g.map_diag(sns.histplot, kde_kws={'color':'black'});\n",
        "#   g.map_upper(corrdot);\n",
        "#   g.fig.suptitle(\"Scatter plot, Correlations and histograms on diagonal\", y=1);\n",
        "#   _ = plt.subplots_adjust(hspace=0.02, wspace=0.02);\n",
        "#   _ = plt.show();\n",
        "\n",
        "# df_ = tXY.loc[(tXY[NumFeatures]>0).all(axis=1), NumFeatures+['Rev']].sample(n=100, random_state=0)\n",
        "# # df_ = df.select_dtypes(include='float').query('AdmDur>0 and InfDur>0 and PrdDur>0 and BncRt>0 and ExtRt>0 and PgVal>0 and SpclDay>0').sample(n=100, random_state=0)\n",
        "# ScatterCorrHist(df_)"
      ],
      "metadata": {
        "id": "i4gelET6Hb2A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmr = Timer()"
      ],
      "metadata": {
        "id": "z4_C58bbHuja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86795dab-b735-4d48-fad9-3dbb2aa80f99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ started. You have 60 sec. Good luck!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr color=red>\n",
        "\n",
        "<font size=5>⏳</font> <strong><font color=orange size=5>Your Code, Documentation, Ideas and Timer - All Start Here...</font></strong>\n",
        "\n",
        "**Student's Section** (between ⏳ symbols): add your code and documentation here."
      ],
      "metadata": {
        "id": "3NcTKbw3KhAn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpyLNt3god0c"
      },
      "source": [
        "## **Task 1. Preprocessing Pipeline**\n",
        "\n",
        "Explain elements of your preprocessing pipeline i.e. feature engineering, subsampling, clustering, dimensionality reduction, etc.\n",
        "1. Why did you choose these elements? (Something in EDA, prior experience,...? Btw, EDA is not required)\n",
        "1. How do you evaluate the effectiveness of these elements?\n",
        "1. What else have you tried that worked or didn't?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30xYIFXAnaPE"
      },
      "source": [
        "**Student's answer:**\n",
        "\n",
        "Things that helped improve accuracy\n",
        "* There are 18 colums in the dataset. 10 of them are integer and 8 of them are float. Only floats were considered and int columns are ignored. I have expanded feature set to from 10 to 18 features by includng int columns as well.\n",
        "* I checked the missing values for imputation. There are no missing values\n",
        "* Feature Selection: Sometimes, not all features are equally informative. I have tried techniques like Recursive Feature Elimination, SelectKBest, or feature importance from tree-based models to select the most relevant features. I used selectKBest\n",
        "Normalize the numeric features to 0 to 1 scale\n",
        "\n",
        "\n",
        "Things that did not help improve accuracy\n",
        "*. Balancing the dataset. The dataset is highly imbalanced. Imbalance ration i s 0.21. Hence I attempted to balance the dataset using SMOTE. However that has reduced accuracy fby 50%\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "N5CSIaFFpRG9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tX, tY = tXY.drop('Rev', axis=1), tXY.Rev      # split into training I/O\n",
        "# Convert integer columns to float to expand feature set\n",
        "int_columns = tX.select_dtypes(include=['int']).columns\n",
        "tX[int_columns] = tX[int_columns].astype(float)\n",
        "tX.info\n",
        "vX[int_columns] = vX[int_columns].astype(float)\n",
        "tX.info\n",
        "\n",
        "NumFeatures = list(tX.select_dtypes(include='float').columns)\n",
        "print('Numeric features: ', NumFeatures)       # numeric/quantitative feature names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob0QG3aUr2xz",
        "outputId": "0cc4b357-eda2-4608-b151-6e23250f24d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of         Adm  AdmDur  Inf  InfDur   Prd   PrdDur  BncRt     ExtRt  PgVal  \\\n",
              "50000   0.0    0.00  0.0     0.0   1.0     0.00   0.16  1.15e-01    0.0   \n",
              "50001   7.0  116.19  0.0     0.0  79.0  2683.58   0.00  1.91e-03    0.0   \n",
              "...     ...     ...  ...     ...   ...      ...    ...       ...    ...   \n",
              "499998  0.0    0.00  0.0     0.0  27.0  1185.14   0.00  1.59e-03    0.0   \n",
              "499999  6.0   51.36  0.0     0.0  59.0  1898.21   0.00  3.22e-03    0.0   \n",
              "\n",
              "        SpclDay    Mo   OS  Bsr  Rgn  TfcTp  VstTp  Wkd  \n",
              "50000       0.0  12.0  2.0  2.0  1.0    9.0    0.0  0.0  \n",
              "50001       0.0   4.0  2.0  3.0  2.0    2.0    1.0  0.0  \n",
              "...         ...   ...  ...  ...  ...    ...    ...  ...  \n",
              "499998      0.0   5.0  2.0  2.0  2.0    3.0    0.0  1.0  \n",
              "499999      0.0  12.0  2.0  2.0  2.0    1.0    0.0  0.0  \n",
              "\n",
              "[450000 rows x 17 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of         Adm  AdmDur  Inf  InfDur   Prd   PrdDur  BncRt     ExtRt  PgVal  \\\n",
              "50000   0.0    0.00  0.0     0.0   1.0     0.00   0.16  1.15e-01    0.0   \n",
              "50001   7.0  116.19  0.0     0.0  79.0  2683.58   0.00  1.91e-03    0.0   \n",
              "...     ...     ...  ...     ...   ...      ...    ...       ...    ...   \n",
              "499998  0.0    0.00  0.0     0.0  27.0  1185.14   0.00  1.59e-03    0.0   \n",
              "499999  6.0   51.36  0.0     0.0  59.0  1898.21   0.00  3.22e-03    0.0   \n",
              "\n",
              "        SpclDay    Mo   OS  Bsr  Rgn  TfcTp  VstTp  Wkd  \n",
              "50000       0.0  12.0  2.0  2.0  1.0    9.0    0.0  0.0  \n",
              "50001       0.0   4.0  2.0  3.0  2.0    2.0    1.0  0.0  \n",
              "...         ...   ...  ...  ...  ...    ...    ...  ...  \n",
              "499998      0.0   5.0  2.0  2.0  2.0    3.0    0.0  1.0  \n",
              "499999      0.0  12.0  2.0  2.0  2.0    1.0    0.0  0.0  \n",
              "\n",
              "[450000 rows x 17 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric features:  ['Adm', 'AdmDur', 'Inf', 'InfDur', 'Prd', 'PrdDur', 'BncRt', 'ExtRt', 'PgVal', 'SpclDay', 'Mo', 'OS', 'Bsr', 'Rgn', 'TfcTp', 'VstTp', 'Wkd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tX_in = tXY[NumFeatures][:30000]\n",
        "tY_in = tXY.Rev[:30000]\n",
        "vX_in = vX"
      ],
      "metadata": {
        "id": "DtMBc0KnSJY6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tX_in.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMXfG6ERtlpW",
        "outputId": "fa4ad194-6f46-4aa4-b6e2-cb195b47ceaf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adm       0\n",
              "AdmDur    0\n",
              "         ..\n",
              "VstTp     0\n",
              "Wkd       0\n",
              "Length: 17, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WpxKeyADutV1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "scaler = StandardScaler()\n",
        "tX_in_scaled = scaler.fit_transform(tX_in)\n",
        "vX_in_scaled = scaler.fit_transform(vX_in)\n"
      ],
      "metadata": {
        "id": "7NzcdkfJSJbu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tX_in_scaled.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3ffVd3hSJfX",
        "outputId": "71075a92-4ca4-4349-dc6e-4f54cf3eaf8a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "510000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f50wZQwavRd_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Selection\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from imblearn.over_sampling import SMOTE\n",
        "# Fit the selector on the training data\n",
        "selector = SelectKBest(score_func=f_classif, k=10)\n",
        "selector.fit(tX_in_scaled, tY_in)\n",
        "\n",
        "# Transform both training and validation/test data\n",
        "tX_selected = selector.transform(tX_in_scaled)\n",
        "vX_selected = selector.transform(vX_in_scaled)  # Assuming vX_scaled is your scaled validation/test data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "2a8uIfq7SJkm",
        "outputId": "b4faa7b3-06c2-4d57-9102-9d1d743d1dab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SelectKBest()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelectKBest()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vX_selected.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcBFHS1A0wrm",
        "outputId": "fa1aac12-f37e-47ad-9b94-e6d88cd0814a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check data impbalance\n",
        "# Count the number of instances in each class\n",
        "class_counts = np.bincount(tY.astype(int))\n",
        "\n",
        "# Calculate the ratio of the minority class to the majority class\n",
        "imbalance_ratio = min(class_counts) / max(class_counts)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Number of instances in each class: {class_counts}\")\n",
        "print(f\"Imbalance ratio: {imbalance_ratio}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEpBQTgEwEaD",
        "outputId": "629bec31-46b4-4601-8444-f98e173948cf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of instances in each class: [349140 100860]\n",
            "Imbalance ratio: 0.2888812510740677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Balance the dataset. This reduced accuracy by 50%. Henced commeneted the code\n",
        "#from imblearn.over_sampling import SMOTE\n",
        "#smote = SMOTE()\n",
        "#tX_balanced, tY_balanced = smote.fit_resample(tX_selected, tY_in)\n",
        "\n"
      ],
      "metadata": {
        "id": "Z5NDL30qwJ62"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2hmwLKH1SJ2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jQ61vFk7SJ5Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGJRwzqHob4o"
      },
      "source": [
        "## **Task 2. Modeling Approach**\n",
        "Explain your modeling approach, i.e. ideas you tried and why you thought they would be helpful.\n",
        "\n",
        "1. How did these decisions guide you in modeling?\n",
        "1. How do you evaluate the effectiveness of these elements?\n",
        "1. What else have you tried that worked or didn't?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi6ZjgtWnb58"
      },
      "source": [
        "**Student's answer:**\n",
        "\n",
        " I tried changing following hyperparameters.\n",
        "\n",
        " The hyperparameters tuning that helped raising accuracy above baseline\n",
        "* Model Architecture: I experimented with different neural network architectures. This includes changing the number of layers, the number of neurons in each layer, and the activation functions. I tried adding new layers and it has helped improving accuracy\n",
        "* Batch Size and Epochs: I experimented with different batch sizes and number of epochs. Sometimes training with a smaller batch size can yield a better generalization.\n",
        "* Regularization: I have added regularization to the layers.\n",
        "* Polynomial features helped improve the performance of a model by capturing interactions between features and considering them in higher-dimensional space.\n",
        "* I have added dropout layer to prevent overfitting\n",
        "\n",
        "I have tried few new models like XGB, Random Forest, Decision Trees and CNN\n",
        "\n",
        "| Model   |          Accuracy |\n",
        "|---------|----------|\n",
        "| Sequential ANN   | 82%        |\n",
        "| CNN     | 81%     |\n",
        "| XGB | 86%     |\n",
        "| Random Forest  | 89%     |\n",
        "| Decision Tree  | 84%     |\n",
        "\n",
        "\n",
        "  \n",
        "  The hyper parameters tuning that did not help improve baseline accuracy\n",
        " * Changing learning rate\n",
        " * Changing size of neurons in hidden layers\n",
        "\n",
        " I have also tried changing model arhitecture to CNN , but that did not help improve accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tX_selected.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs6CxpdczQMm",
        "outputId": "aaf63f75-77b5-43c5-a5cd-a6450cfc1655"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Polynomial Features\n",
        "poly = PolynomialFeatures(degree=2)  # You can change the degree\n",
        "tX_poly = poly.fit_transform(tX_selected)\n",
        "vX_poly = poly.fit_transform(vX_selected)\n",
        "\n"
      ],
      "metadata": {
        "id": "bQ1_dFmp1DFu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJs0jS4fIO1j"
      },
      "source": [
        "#Below is a Sequenctial ANN model with regualrization, drop out and more layers . This gives accuracy of 82%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%time\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "tf.random.set_seed(0)   # always seed your experiments\n",
        "Init = keras.initializers.RandomNormal(seed=0)\n",
        "\n",
        "\n",
        "\n",
        "m = keras.models.Sequential([\n",
        "    Flatten(input_shape=[tX_poly.shape[1]], name='input'),\n",
        "    Dense(16, activation=\"relu\", kernel_initializer=Init, kernel_regularizer=regularizers.l2(0.0001), name='hidden4'),# I added this layer\n",
        "    Dropout(0.005),\n",
        "    Dense(50, activation=\"relu\", kernel_initializer=Init, kernel_regularizer=regularizers.l2(0.0001),  name='hidden'),\n",
        "    Dropout(0.005),\n",
        "    Dense(32, activation=\"relu\", kernel_initializer=Init, kernel_regularizer=regularizers.l2(0.0001), name='hidden2'),   # I added this layer\n",
        "    Dropout(0.005),\n",
        "    Dense(16, activation=\"relu\", kernel_initializer=Init, kernel_regularizer=regularizers.l2(0.0001), name='hidden3'),   # I added this layer\n",
        "    Dropout(0.005),\n",
        "    Dense(1, activation='sigmoid', kernel_initializer=Init, name='output')])\n",
        "m.summary()\n",
        "m.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
        "hist = m.fit(tX_poly, tY_in, epochs=15, validation_split=0.3, batch_size=32)\n"
      ],
      "metadata": {
        "id": "54INeiMDAGpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86185b56-544c-4d29-f32d-a42d2d26cbb0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (Flatten)             (None, 66)                0         \n",
            "                                                                 \n",
            " hidden4 (Dense)             (None, 16)                1072      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " hidden (Dense)              (None, 50)                850       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " hidden2 (Dense)             (None, 32)                1632      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " hidden3 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,099\n",
            "Trainable params: 4,099\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "657/657 [==============================] - 12s 12ms/step - loss: 0.4499 - accuracy: 0.8015 - val_loss: 0.4230 - val_accuracy: 0.8093\n",
            "Epoch 2/15\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.4096 - accuracy: 0.8181 - val_loss: 0.4138 - val_accuracy: 0.8174\n",
            "Epoch 3/15\n",
            "657/657 [==============================] - 6s 10ms/step - loss: 0.4041 - accuracy: 0.8207 - val_loss: 0.4137 - val_accuracy: 0.8136\n",
            "Epoch 4/15\n",
            "657/657 [==============================] - 2s 3ms/step - loss: 0.4010 - accuracy: 0.8227 - val_loss: 0.4100 - val_accuracy: 0.8190\n",
            "Epoch 5/15\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.3980 - accuracy: 0.8245 - val_loss: 0.4193 - val_accuracy: 0.8184\n",
            "Epoch 6/15\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.3968 - accuracy: 0.8246 - val_loss: 0.4101 - val_accuracy: 0.8200\n",
            "Epoch 7/15\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.3950 - accuracy: 0.8256 - val_loss: 0.4084 - val_accuracy: 0.8208\n",
            "Epoch 8/15\n",
            "657/657 [==============================] - 3s 4ms/step - loss: 0.3940 - accuracy: 0.8268 - val_loss: 0.4083 - val_accuracy: 0.8211\n",
            "Epoch 9/15\n",
            "657/657 [==============================] - 3s 4ms/step - loss: 0.3933 - accuracy: 0.8274 - val_loss: 0.4105 - val_accuracy: 0.8197\n",
            "Epoch 10/15\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.3937 - accuracy: 0.8261 - val_loss: 0.4046 - val_accuracy: 0.8226\n",
            "Epoch 11/15\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.3909 - accuracy: 0.8290 - val_loss: 0.4076 - val_accuracy: 0.8219\n",
            "Epoch 12/15\n",
            "657/657 [==============================] - 5s 7ms/step - loss: 0.3901 - accuracy: 0.8294 - val_loss: 0.4039 - val_accuracy: 0.8259\n",
            "Epoch 13/15\n",
            "657/657 [==============================] - 2s 4ms/step - loss: 0.3898 - accuracy: 0.8304 - val_loss: 0.4080 - val_accuracy: 0.8252\n",
            "Epoch 14/15\n",
            "657/657 [==============================] - 3s 4ms/step - loss: 0.3885 - accuracy: 0.8310 - val_loss: 0.4060 - val_accuracy: 0.8252\n",
            "Epoch 15/15\n",
            "657/657 [==============================] - 3s 4ms/step - loss: 0.3868 - accuracy: 0.8327 - val_loss: 0.4017 - val_accuracy: 0.8279\n",
            "CPU times: user 50.3 s, sys: 1.82 s, total: 52.2 s\n",
            "Wall time: 1min 26s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Let try with XGB Model.\n",
        "#Observation: XGB Model performs a lot better as compared t sequential model\n",
        "# Accuracy is up to 86%"
      ],
      "metadata": {
        "id": "PVa7k2E2-NBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Polynomial Features\n",
        "#poly = PolynomialFeatures(degree=2)  # You can change the degree\n",
        "#tX_poly = poly.fit_transform(tX)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(tX_poly, tY_in, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the XGBoost model\n",
        "m = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Create the XGBoost model with custom hyperparameters\n",
        "\n",
        "m = xgb.XGBClassifier(\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    n_estimators=100,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.01,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    gamma=0,\n",
        "    reg_alpha=0,\n",
        "    reg_lambda=1,\n",
        "    scale_pos_weight=1\n",
        ")\n",
        "\n",
        "# Fit the model on the training data\n",
        "m.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = m.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "6knmvip-6_Y4",
        "outputId": "6acd6c71-786d-4901-a23e-18996e4572c8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport xgboost as xgb\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.preprocessing import PolynomialFeatures\\n\\n# Polynomial Features\\n#poly = PolynomialFeatures(degree=2)  # You can change the degree\\n#tX_poly = poly.fit_transform(tX)\\n\\n# Split the data into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(tX_poly, tY_in, test_size=0.2, random_state=42)\\n\\n# Create the XGBoost model\\nm = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\\n\\n# Create the XGBoost model with custom hyperparameters\\n\\nm = xgb.XGBClassifier(\\n    use_label_encoder=False,\\n    eval_metric='logloss',\\n    n_estimators=100,\\n    max_depth=3,\\n    learning_rate=0.01,\\n    subsample=0.8,\\n    colsample_bytree=0.8,\\n    gamma=0,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1\\n)\\n\\n# Fit the model on the training data\\nm.fit(X_train, y_train)\\n\\n# Predict on the test set\\ny_pred = m.predict(X_test)\\n\\n# Calculate and print the accuracy\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f'Test Accuracy: {accuracy}')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lets try RandomForest Model"
      ],
      "metadata": {
        "id": "Ap3kZe0G_Yyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "%%time\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(tX_poly, tY_in, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the Random Forest model with custom hyperparameters\n",
        "\n",
        "\n",
        "# Create the model\n",
        "#m = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "m = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    max_features='auto',\n",
        "    bootstrap=True,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "m = RandomForestClassifier(max_features='auto', n_estimators=200, random_state=0)\n",
        "\n",
        "\n",
        "\n",
        "# Fit the model on the training data\n",
        "m.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = m.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "QxfsD-_c_bpf",
        "outputId": "a3f0b78c-28c3-4c57-df32-5f10c32b2804"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n%%time\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.model_selection import train_test_split\\n\\n\\n\\n# Split the data into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(tX_poly, tY_in, test_size=0.2, random_state=42)\\n\\n# Create the Random Forest model with custom hyperparameters\\n\\n\\n# Create the model\\n#m = RandomForestClassifier(n_estimators=100, random_state=0)\\n\\nm = RandomForestClassifier(\\n    n_estimators=100,\\n    max_depth=None,\\n    min_samples_split=2,\\n    min_samples_leaf=1,\\n    max_features='auto',\\n    bootstrap=True,\\n    random_state=0\\n)\\n\\nm = RandomForestClassifier(max_features='auto', n_estimators=200, random_state=0)\\n\\n\\n\\n# Fit the model on the training data\\nm.fit(X_train, y_train)\\n\\n# Predict on the test set\\ny_pred = m.predict(X_test)\\n\\n# Calculate and print the accuracy\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f'Test Accuracy: {accuracy}')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest model. The score is same as above (88.33%)"
      ],
      "metadata": {
        "id": "OKfosLXxOqMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest with CV\n",
        "'''\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(tX_poly, tY_in, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the Random Forest model with custom hyperparameters\n",
        "m = RandomForestClassifier(max_features='auto', n_estimators=200, random_state=0)\n",
        "\n",
        "# Perform cross-validation and compute the mean score\n",
        "cv_scores = cross_val_score(m, X_train, y_train, cv=5)\n",
        "mean_cv_score = np.mean(cv_scores)\n",
        "\n",
        "# Print the mean cross-validation score\n",
        "print(f'Mean Cross-Validation Score: {mean_cv_score}')\n",
        "\n",
        "# Fit the model on the training data\n",
        "m.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = m.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "yHuLKwJLNPG8",
        "outputId": "6bae8878-ef0c-4709-e79c-f5fa34ab48d3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import cross_val_score, train_test_split\\nfrom sklearn.preprocessing import PolynomialFeatures\\nimport numpy as np\\n\\n\\n# Split the data into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(tX_poly, tY_in, test_size=0.2, random_state=42)\\n\\n# Create the Random Forest model with custom hyperparameters\\nm = RandomForestClassifier(max_features='auto', n_estimators=200, random_state=0)\\n\\n# Perform cross-validation and compute the mean score\\ncv_scores = cross_val_score(m, X_train, y_train, cv=5)\\nmean_cv_score = np.mean(cv_scores)\\n\\n# Print the mean cross-validation score\\nprint(f'Mean Cross-Validation Score: {mean_cv_score}')\\n\\n# Fit the model on the training data\\nm.fit(X_train, y_train)\\n\\n# Predict on the test set\\ny_pred = m.predict(X_test)\\n\\n# Calculate and print the accuracy\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f'Test Accuracy: {accuracy}')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Let's try decision Tree model/\n",
        "## Accuracy is 84%"
      ],
      "metadata": {
        "id": "sjIZEmLZOYYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(tX_poly, tY_in, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the Decision Tree model\n",
        "m = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "# Fit the model on the training data\n",
        "m.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = m.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "lQcOrX8oOWwf",
        "outputId": "c950f700-cd8c-4f4f-b951-f26e7c77fc00"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.preprocessing import PolynomialFeatures\\n\\n\\n\\n# Split the data into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(tX_poly, tY_in, test_size=0.2, random_state=42)\\n\\n# Create the Decision Tree model\\nm = DecisionTreeClassifier(random_state=0)\\n\\n# Fit the model on the training data\\nm.fit(X_train, y_train)\\n\\n# Predict on the test set\\ny_pred = m.predict(X_test)\\n\\n# Calculate and print the accuracy\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f'Test Accuracy: {accuracy}')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#GridSearchCV to find best params of RandomForest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import ParameterGrid, train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(tX_poly, tY_in, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the grid of hyperparameters to search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "# Create a Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Create a list to store the average cross-validation score for each combination of parameters\n",
        "scores = []\n",
        "\n",
        "# Loop over each combination of parameters\n",
        "for params in ParameterGrid(param_grid):\n",
        "\n",
        "    # Set the parameters on the model\n",
        "    rf_model.set_params(**params)\n",
        "\n",
        "    # Perform cross-validation and compute the mean score\n",
        "    cv_scores = cross_val_score(rf_model, X_train, y_train, cv=3)\n",
        "    mean_cv_score = np.mean(cv_scores)\n",
        "\n",
        "    # Print the parameters and the mean score\n",
        "    print(f'Parameters: {params}')\n",
        "    print(f'Mean CV Score: {mean_cv_score}')\n",
        "\n",
        "    # Append the score to the scores list\n",
        "    scores.append(mean_cv_score)\n",
        "\n",
        "# Get the parameters that gave the highest mean cross-validation score\n",
        "best_params = ParameterGrid(param_grid)[np.argmax(scores)]\n",
        "print(f'Best parameters: {best_params}')\n",
        "\n",
        "# Fit the model on the training data using the best parameters\n",
        "best_rf_model = RandomForestClassifier(**best_params, random_state=0)\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "oM763pI-jFF7",
        "outputId": "ced1e89c-dd6c-4d3d-a49e-5a301fa45506"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n#GridSearchCV to find best params of RandomForest\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import ParameterGrid, train_test_split, cross_val_score\\nfrom sklearn.preprocessing import PolynomialFeatures\\nimport numpy as np\\n\\n\\n# Split the data into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(tX_poly, tY_in, test_size=0.2, random_state=42)\\n\\n# Define the grid of hyperparameters to search\\nparam_grid = {\\n    'n_estimators': [100, 200],\\n    'max_depth': [None, 10],\\n    'min_samples_split': [2, 5],\\n    'min_samples_leaf': [1, 2],\\n    'max_features': ['auto', 'sqrt']\\n}\\n\\n# Create a Random Forest model\\nrf_model = RandomForestClassifier(random_state=0)\\n\\n# Create a list to store the average cross-validation score for each combination of parameters\\nscores = []\\n\\n# Loop over each combination of parameters\\nfor params in ParameterGrid(param_grid):\\n\\n    # Set the parameters on the model\\n    rf_model.set_params(**params)\\n\\n    # Perform cross-validation and compute the mean score\\n    cv_scores = cross_val_score(rf_model, X_train, y_train, cv=3)\\n    mean_cv_score = np.mean(cv_scores)\\n\\n    # Print the parameters and the mean score\\n    print(f'Parameters: {params}')\\n    print(f'Mean CV Score: {mean_cv_score}')\\n\\n    # Append the score to the scores list\\n    scores.append(mean_cv_score)\\n\\n# Get the parameters that gave the highest mean cross-validation score\\nbest_params = ParameterGrid(param_grid)[np.argmax(scores)]\\nprint(f'Best parameters: {best_params}')\\n\\n# Fit the model on the training data using the best parameters\\nbest_rf_model = RandomForestClassifier(**best_params, random_state=0)\\nbest_rf_model.fit(X_train, y_train)\\n\\n# Predict on the test set\\ny_pred = best_rf_model.predict(X_test)\\n\\n# Calculate and print the accuracy\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f'Test Accuracy: {accuracy}')\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changed Model Architecture to CNN . However accuracy did not improve."
      ],
      "metadata": {
        "id": "K5pCsu7_RsQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming tX_scaled and tY are your preprocessed features and labels\n",
        "\n",
        "# Reshaping the data to be 3D as needed for CNN\n",
        "tX_reshaped = tX_poly.reshape(tX_poly.shape[0], tX_poly.shape[1], 1)\n",
        "\n",
        "# Model\n",
        "model = Sequential()\n",
        "\n",
        "# Adding Convolutional Layers\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(tX_reshaped.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "\n",
        "# Adding Dense Layers\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(tX_reshaped, tY, epochs=10, batch_size=32, validation_split=0.2)\n",
        "'''"
      ],
      "metadata": {
        "id": "YXE4CQt2RKYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4da28b7c-f6df-4c0c-c1fb-95cc9cd7990b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport tensorflow as tf\\nfrom tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\\nfrom tensorflow.keras import Sequential\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Assuming tX_scaled and tY are your preprocessed features and labels\\n\\n# Reshaping the data to be 3D as needed for CNN\\ntX_reshaped = tX_poly.reshape(tX_poly.shape[0], tX_poly.shape[1], 1)\\n\\n# Model\\nmodel = Sequential()\\n\\n# Adding Convolutional Layers\\nmodel.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(tX_reshaped.shape[1], 1)))\\nmodel.add(MaxPooling1D(pool_size=2))\\nmodel.add(Flatten())\\n\\n# Adding Dense Layers\\nmodel.add(Dense(50, activation='relu'))\\nmodel.add(Dense(1, activation='sigmoid'))\\n\\n# Compile the model\\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\\n\\n# Fit the model\\nmodel.fit(tX_reshaped, tY, epochs=10, batch_size=32, validation_split=0.2)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vX.reset_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "hJMaPHYVyiHc",
        "outputId": "03b03eaa-d621-4bd6-afe2-c7aba1cce9ae"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       index  Adm  AdmDur  Inf  InfDur   Prd   PrdDur     BncRt     ExtRt  \\\n",
              "0          0  0.0    0.00  0.0     0.0  18.0   132.99  3.82e-02  5.45e-02   \n",
              "1          1  1.0    0.00  0.0     0.0  37.0  1150.20  1.25e-03  3.03e-02   \n",
              "...      ...  ...     ...  ...     ...   ...      ...       ...       ...   \n",
              "49998  49998  4.0  357.05  0.0     0.0  27.0  1278.00  0.00e+00  6.81e-03   \n",
              "49999  49999  0.0    0.00  0.0     0.0  26.0  1646.42  7.55e-03  3.25e-02   \n",
              "\n",
              "       PgVal  SpclDay    Mo   OS  Bsr  Rgn  TfcTp  VstTp  Wkd  \n",
              "0       0.00      0.0   4.0  3.0  1.0  1.0    2.0    0.0  1.0  \n",
              "1       0.00      0.0  11.0  2.0  2.0  4.0    2.0    0.0  1.0  \n",
              "...      ...      ...   ...  ...  ...  ...    ...    ...  ...  \n",
              "49998  14.54      0.0  11.0  2.0  2.0  5.0    2.0    0.0  0.0  \n",
              "49999   0.00      0.0   2.0  2.0  2.0  4.0    3.0    0.0  1.0  \n",
              "\n",
              "[50000 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00c00451-7f11-463f-bad2-76960d878c6d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Adm</th>\n",
              "      <th>AdmDur</th>\n",
              "      <th>Inf</th>\n",
              "      <th>InfDur</th>\n",
              "      <th>Prd</th>\n",
              "      <th>PrdDur</th>\n",
              "      <th>BncRt</th>\n",
              "      <th>ExtRt</th>\n",
              "      <th>PgVal</th>\n",
              "      <th>SpclDay</th>\n",
              "      <th>Mo</th>\n",
              "      <th>OS</th>\n",
              "      <th>Bsr</th>\n",
              "      <th>Rgn</th>\n",
              "      <th>TfcTp</th>\n",
              "      <th>VstTp</th>\n",
              "      <th>Wkd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>132.99</td>\n",
              "      <td>3.82e-02</td>\n",
              "      <td>5.45e-02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1150.20</td>\n",
              "      <td>1.25e-03</td>\n",
              "      <td>3.03e-02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>49998</td>\n",
              "      <td>4.0</td>\n",
              "      <td>357.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1278.00</td>\n",
              "      <td>0.00e+00</td>\n",
              "      <td>6.81e-03</td>\n",
              "      <td>14.54</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>49999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1646.42</td>\n",
              "      <td>7.55e-03</td>\n",
              "      <td>3.25e-02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00c00451-7f11-463f-bad2-76960d878c6d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00c00451-7f11-463f-bad2-76960d878c6d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00c00451-7f11-463f-bad2-76960d878c6d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePSyPLcRzC6r",
        "outputId": "2e43dd6f-e273-4e89-a420-ae596e995906"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vX.index+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OzSlNob2Dnk",
        "outputId": "cbfcb03b-db93-4f1e-8233-299c06dbcca4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([    1,     2,     3,     4,     5,     6,     7,     8,     9,\n",
              "               10,\n",
              "            ...\n",
              "            49991, 49992, 49993, 49994, 49995, 49996, 49997, 49998, 49999,\n",
              "            50000],\n",
              "           dtype='int64', length=50000)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pY = pd.DataFrame(m.predict(vX_poly),index=vX.index+1, columns=['Rev'])\n",
        "ToCSV(pY.round(0).astype(int), 'Ravindra_shop_v5')\n",
        "tXY.Rev.value_counts()/len(tXY)                # distribution of training target level\n",
        "pY.round(0).astype(int).value_counts()/len(pY) # distribution of test target level"
      ],
      "metadata": {
        "id": "Q_In-QcBCCPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328a75b8-00c2-4d98-f273-3d7b3079798f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 3s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    0.78\n",
              "1.0    0.22\n",
              "Name: Rev, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Rev\n",
              "0      0.86\n",
              "1      0.14\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **References:**"
      ],
      "metadata": {
        "id": "pzBsjCvS_kEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Textbook:\n",
        "\n",
        "Hastie, T., Tibshirani, R., & Friedman, J. (2009). The elements of statistical learning: data mining, inference, and prediction. Springer Science & Business Media.\n",
        "\n",
        "\n",
        "Online Documentation:\n",
        "TensorFlow. (n.d.). TensorFlow Core.  from https://www.tensorflow.org/api_docs\n"
      ],
      "metadata": {
        "id": "2kr8Q-9T_nAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=5>⌛</font> <strong><font color=orange size=5>Do not exceed competition's runtime limit!</font></strong>\n",
        "\n",
        "<hr color=red>\n"
      ],
      "metadata": {
        "id": "DoF2GoB_QGw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmr.ShowTime()    # measure Colab's runtime. Do not remove. Keep as the last cell in your notebook."
      ],
      "metadata": {
        "id": "bD1sdgYbNWQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc488a4e-ac4c-4dc3-8b5c-ddc9248e9a42"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91m\u001b[1mRuntime is 93 sec > 60 sec limit!!!\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUStTaN4uo_Z"
      },
      "source": [
        "## 💡**Starter Ideas**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**\n",
        "1. Tune model hyperparameters, batch size, optimizer, NN layers\n",
        "\n",
        "**Features**\n",
        "1. Try to linear and non-linear feature normalization: shift/scale, log, divide features by features (investigate scatterplot matrix)\n",
        "1. Try higher order feature interactions and polynomial features on a small subsample. Then identify key features or select key principal components. The final model can be trained on a larger or even full training sample. You can use [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) to reduce the feature set\n",
        "1. Incorporate categorical features (appropriately encoded)\n",
        "  1. E.g. you could replace codes (or groups of codes) with their frequencies, which may capture the implied \"distance\" or rarity between category levels.\n",
        "  1. If encoding ordinal features with integers, should non-equidistant values be considered?\n",
        "\n",
        "**Training observations**\n",
        "1. Try clustering methods to remove similar observations. You may also try dimension reduction methods (eg. PCA) on the transposed data matrix (if it has scaled numeric features).\n",
        "1. Look for and deal with outliers or influential points in the training set\n",
        "1. Deal with **imbalanced sample**: oversample smaller class, or undersample larger class, or provide observation weights or provide class weights, or seek a suitable loss function\n",
        "1. Investigate distributions of features. Any missing values? Any zero values?\n",
        "\n",
        "**Predictions**\n",
        "1. Evaluate predictions and focus on poorly predicted \"groups\":\n",
        "  1. Strongest misclassifications. E.g. the model is very confident about the wrong label\n",
        "  1. Evaluate predictions near decision boundaries.\n",
        "\n",
        "**EDA and Domain Expertise**\n",
        "1. Do a thorough EDA: look for feature augmentations that result in linear decision boundaries between pairs of classes.\n",
        "1. Learn about the domain: how should output relate to features? How do month or weekend impact users' buying activity?\n",
        "  1. User Agent [&#127910;](https://www.youtube.com/results?search_query=user+agent+browser), Google Analytics [&#127910;](https://www.youtube.com/results?search_query=google+analytics), tracking online shopping intent [&#127910;](https://www.youtube.com/results?search_query=tacking+online+shopping+intent), [📄](https://scholar.google.com/scholar?q=tracking+online+shopping+intent)"
      ],
      "metadata": {
        "id": "q4QO-u3t8xAO"
      }
    }
  ]
}